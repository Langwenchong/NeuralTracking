# DynamicFusion + NeuralNRT代码流程总结

## DynamicFusion初始化

### RGBDVideoLoader数据加载初始化

1. seq_dir指定输入数据文件夹包括(Color,Depth,Intrinsics)
2. 查询graph_config.json设定图配置参数，如果没有使用默认参数graph_generation_parameters
3. graph_dicts存储每一帧节点图的信息包括存储nodes存储文件路径，edges，权重，每一个像素对应的三维点的参考nodes，nodes影响范围
4. 创建存储tsdf,标准空间mesh,形变后的帧mesh，更新后图等文件夹

### Deformnet_runner初始化(负责整个形变的流程)

1. 加载DeformNet模型以及权重参数，这个是NeuralNRT的部分
2. 具体的形变优化模型是DeformNet,包括2d光流推理PWCNet，像素权重推理MaskNet以及非刚性约束arap等高斯牛顿迭代求解的部分

## DynamicFusion主函数运行

### run函数

1. 接收开始帧(标准帧)，每一次间隔的帧，关键帧，tsdf volume的voxel初始尺寸(m)参数
2. 对于第一帧进行特殊初始化，根绝第一帧的数据(注意是6,H,W的图前3维为rgb后三维为点的三维坐标)构造graph_data以及此时的graph_deformation_data初始化为空，并根据第一帧的最大深度初始化tsdf volume，注意这个返还的tsdf示例同时包含了tsdfvolume本身以及形变更新所需要的graph_dict以及warpfield
3. 注意之前create_graph_data_using_depth根据输入的深度图计算过一个深度图像素的mask，但是深度图mask合法只能说明这个像素对应的点是三维空间中真实存在的，但是具体是否属于集合表面要看pixel_anchor，因为pixel_anchor是根据erode后的点计算投影得到的，因此这里紧接着对输入的第一帧进行mask筛选，只有在像素对应的点有关联控制点的区域是真正的表面，这里接收第一帧的数据进行tsdf第一次integrate
4. 可视化这里左侧是可视化当前的motion graph运动图，右侧是标准空间的mesh
5. 接下来就是获取每一个target帧并优化moation graph形变后再integrate更新tsdf,注意这里的第一帧是使用的RGBDVideoLoader的get_source_data函数获取而接下来循环的每一帧是调用的get_target_data函数获取
6. image_path是存储当前已经计算过形变的帧存储到一个路径中，而deformation_path是存储形变的数据，如果已经有了说明是中途停止了直接读入计算后的形变就可以了，否则如果updated_garaph为False说明还没有更新过motion graph则要优化估计形变并更新motion_graph
7. 得到优化后的graph_deformation_data后将tsdf变形到当前帧fusion计算新的tsdf值并存储当前更新后的tsdf
8. 之后存储融合当前帧后的标准空间mesh(一般会多了更多的顶点)，然后存储形变后的mesh，这里要注意和integrate函数中虽然都调用了tsdf.warpfield.deform_tsdf函数但是参数不一样了这里多了一个verts因为我们已经知道了标准空间中有哪些点了因此直接对这个fusion的标准空间的mesh顶点进行形变就可以了之后同样保存
9. 之后可视化查看一下窗口中有4个图分别是标准空间的mesh+motion graph，当前帧的target点云，fusion后标准空间的mesh形变后的deformed_mesh以及形变后的motion graph
10. 之后还有一个后处理环节，我们需要对graph数据进行更新，因为多出了许多新的顶点需要添加新的控制节点即更新motion_graph的顶点数，权重数以及为新控制顶点初始化形变参数
11. 自此我们完成了对graph_data的更新，注意我们最后还要保存graph_data，注意这里保存的graph_data是包括原先关节点node形变以及新添加的关节点node的静态graph，而deformation存储的mat只包含了对原先graph旧节点的形变更新相关的信息
12. 最后这个逐渐优化形变的过程会有误差累积即使误差最终会稳定在一个常数值附近，但是由于随着视频的延长，我们之前所说的source和target相关像素会越来越少的问题需要解决，因为这里一直计算的都是标准空间即第一帧到当前时刻t帧的形变，因此我们为了解决后面很难找到匹配点的问题，需要在关键帧重新初始化标准空间mesh等，这个问题我认为可以通过不断更新source图解决

### RGBDVideoLoader get_graph函数

根据接收的index查询当前帧的节点图graph_dicts是否存在，如果不存在则根据当前的深度图以及预设定的graph_generateion_parameters创建节点图，最后根据已经存在或者刚刚创建好的graph_dicts存储路径加载当前帧的graph_dicts并返还

### create_graph_data_using_depth函数

1. MAX_TRAIANGLE_DISTANCE决定了点的最大距离根据三角面的最大距离删除离群点
2. NUM_NEIGHBORS决定的是三维nodes之间的相邻点个数，而PIXEL_ANCHORS决定的是每一个像素对应的三维点自己的相邻空间nodes节点
3. MASK决定合法的三维点，这里可以是预先计算好的或者是要求当前的深度图的像素深度要大于0
4. compute_mesh_from_depth_c函数根据输入的点图在合法点处创建mesh点并进一步根据MAX_TRIANGLE_DISTANCE删除部分离群点后返还mesh的点以及对应的点投影uv坐标以及faces
5. erode_mesh_c进一步删除邻居点少的点，这里是通过返还mask码实现以保证nodes不会出现在mesh边界,因此实际上合法的待选nodes点是valid_vertices = non_erode_vertices注意是mask
6. sample_nodes_c根据NODE_CONVERAGE抽取nodes,返还node_coords三维坐标于对应的索引node_indices
7. 注意创建的关于nodes的边和pixel_anchors的区别，graph_edges默认是可以最多8条边对应每一个node最近的8个相邻node，graph_edges_distances同上，注意这里的node_to_vertex_distances包含了未erocde的点
8. compute_edges_geodesic_c计算node之间的边距离注意这里是测地距离不似乎欧氏距离常用于图之间边的计算，以及返还node的边于距离权重等，这里的边是n->m的表示形式，权重是归一化后的(注意并不是每一个node相邻点node都有8个只是寻找最多8个)，node_to_vertex_distance存储每一个节点到点的距离但是当超过阈值时设置为-1表示无法抵达
9. 创建node黑名单删除没有充足邻居node的节点，这里默认要求至少要有2个邻居node
10. 用compute_pixel_anchors_geodesic_c计算每一个像素点对应的三维点最近的4个控制节点node索引并返还对应的控制权重，有的像素可能没有对应的合法三维点此时存储的anchors就全为-1
11. 根据valid_nodes_mask将不合法的node(邻居个数少于2个)的删除，需要更新边，边权重，索引等
12. 由于删除了部分node，因此索引不连续了需要重新排列，这里需要进一步更新以上graph的所有属性包括边，边权重，pixel_anchors等
13. 计算nodes所属群，如果某个群的数量少于2个则删除这几个关键点node，这里是对漂浮的区域进行删除
14. 最后保存当前这一帧的graph数据，用bin格式存储并返还graph_path_dict即graph各个属性存储的文件路径

### TSDFVolume初始化函数

1. 首先根据相机内参计算视锥体(相机坐标系)，view_frust_pts存储了5个点的三维坐标，分别是以图像坐标系(u,v)为左上角起点拼接上深度分别为(0,0,0)(0,0,max_depth)(0,im_h,max_depth),(im_w,0.max_depth),(im_w,im_h,max_depth)反投影到相机坐标系中因此这个视棱锥的中心起点是图像左上角
2. 根据5个点在三个维度的最大最小值得到volume的boundings，这里用vol_bnds存储
3. 根据voxel_size计算volume各个轴的voxel个数即voxel_dim
4. 重新计算bnds，因为bnds未必是voxel_size的整数倍此时要向下取整并且以各个轴边界的最小值作为起点vol_origin
5. 初始化weight_volume为全0，color是256\*256这里后面会解释实际上R\*G\*B的值因此这里的256\*256就是(1,1,1)全白的值
6. 决定是否使用gpu，如果使用gpu，则需要将volume存储到gpu中同时fusion代码也要是gpu版本，这里仅仅使用cpu即可因为不会太慢
7. 使用meshgrid计算volume中每一个voxel的三维索引坐标注意不是真实的以m为单位的坐标值而只是索引

### WarpField初始化函数

1. 这里主要是定义根据graph_dict当前存储的图信息以及当前的tsdf进行形变更新graph_dict
2. 这里的update_kdtree是建立一个KDTree存储当前图的nodes
3. 提前根据tsdf的vox_coords计算tsdf每一个voxel的相机坐标系的点坐标
4. 注意TSDFVolume中定义了一个warpfield实例，而warpfiled又存储了tsdfvolume实例以便对tsdf进行一系列更新形变操作

### TSDF integrate函数(第一次)

1. 这里读入6通道的输入数据进行tsdfvolume的更新，其中前三通道对应的是color图，后面三通道对应的是vertex图，最后一个通道是z也就是depth图
2. 紧接着将图颜色范围从[0,1]拓展到[0,255]后将三通道值RGB转换为单通道值
3. 这里的NeuralTracking默认相机位置不变，如果相机位置也是变化的则还需要初始化cam_pose多一个相机位置形变的环节
4. 此时还没有对应的形变估计，因此graph_deformation_data是None，因此不需要将tsdf从标准空间形变到t帧，因为默认第一帧就是标准空间状态，直接得到warpfield现在维护的world_pts即可
5. rigid_transform就是对tsdf的点整体进行cam_pose导致的刚性形变
6. 将tsdf的voxel点坐标投影到图像坐标系，并计算valid_pix去除超出视锥体的点(注意此时可能会有多个voxel投影对应同一个pix，只不过pix_z值会不同)
7. 根据当前可见的voxel区域的pix坐标采样输入的depth_im数据
8. 计算depth_diff注意必须是采样的depth_val-pix_z这样的话volume中位于depth之前更靠近相机的点会是正值也即表面外部是正值，而远于相机的点计算出来的是负值即表面内部是负值，并且注意此时不是每一个像素对应一个sdf而是每一个voxel对应一个sdf值
9. 之后进行截断，首先要求合法的voxel坐标点应该是首先保证采样的深度大于0，且depth_diff≥-截断值也就是只对(更靠近相近的voxel，比表面更远的截断距离边界]范围的voxel进行保留为合法值进行更新
10. 并且dist进一步对depth_diff的正值进行处理最大保留为1，因此最终的dist是(-∞,1)这也保证了对合法的voxel处不会进行过大的sdf fusion
11. 使用integrate_tsdf计算这些合法的voxel的新的sdf于权重值后重新赋值
12. 颜色也是类似的，只不过要注意这里的颜色存储是单通道，同时需要加上边界限定以防出现非法颜色值

### TSDF integrate_tsdf函数

1. 这里接收合法要更新的voxel的旧的权重以及当前观察帧的数据权重对这些合法的tsdf_vol的voxel进行更新
2. 计算新的权重并返还新的权重值以及更新后的tsdf_vol，注意这里的更新方法，obs_weight默认赋值为了1更好的方法需要结合当前观察方向的向量和法线方向进行计算
3. 这里的注解@staticmethod表示这个函数是类静态函数，因此没有形参实例本身self，而@njit是一个加速库，他可以借助多线程加速for循环的执行速度(但是这个for循环要保证每一个样例之间没有强数据相关性，我认为这里就类似于GPU实现，只不过具体的操作又比较复杂很难将数据作为一个张量通过矩阵运算实现)

### RGBDVideoLoader get_xxx_data函数

1. get_source_data与get target_data函数实际上都是调用DeformDataset.load_image函数得到返还处理后的图片
2. 只不过get_source_data由于是首次加载，图片在加载过程中可能会涉及到裁剪出里导致相机内参发生变化因此get_source_data多了一个更新内参的环节
3. 而get_target_data由于后续帧格式都一样因此都是用第一帧对应的相机内参就可以了，这里只需要返还图片以及一个新的参数target_boundary_mask

### DeformDataset loadimage函数

DeformDataset是DeepDeform对应的数据集的加载类，这个数据集包括了采集的RGBD以及对应的gt flow等主要是一开始用于训练NeuralNRT的，因此get_item函数包含了loadimage等一系列函数，而loadimage就是根据当前的数据路径加载图片，具体是通过进一步调用create_image函数实现，这里主要是给定一些参数即预设的加载图片的分辨率，是否计算裁剪，返还cropper的参数以及max_boundary_dist和是否计算boundary_mask

### DeformDataset create_image函数

1. 读入深度图与color图首先要计算返还对应的6通道数据(即三通道颜色+三通道的点图拼接)，并且如果裁剪的话返还裁剪器并在这里使用裁剪器对图片进行裁剪
2. 如果要计算max_boundary_mask，则进一步调用imagepro的compute_boundary_mask

### Utils/Image_pro compute_boundary_mask函数

这里存放了关于图片处理的一些函数，其中这个函数主要是计算图像边界的掩码，计算方法就是对图像分别像上下左右移动一个像素并计算逐像素差值，如果大于预设深度差值0.1其实就是0.1m则认为是边界，因此返还的是物体和周围空洞区域的边界掩码

### run_model/Deformnet_runner call函数

1. 负责在调用DeformNet之前处理数据格式以及返还数据格式
2. 由于之前的数据都是numpy格式因此首先需要转换为tensor同时DeformNet是可以批处理的，因此这里需要修改为mini-batch格式，如果要处理多视图则可以设置batch≥2以便批处理
3. 返还数据格式仍然修改为numpy字典，并且将占据很大空间的无用数据进行删除

### model/DeformNet forward函数

1. x1是source_data即第一帧标准空间的数据，x2是target_data即当前帧的数据(6通道)
2. convergence_info存储的是当前形变场估计的相关信息包括总损失，刚性损失，data项损失等
3. flow2是下采样后图片的密集2d光流，features2是光流估计模块的中间特征，这里的features2与论文中一样用于后面的masknet输入，进一步根据当前的flow2上采样回原分辨率图片，并且这里参考PWCNet需要对应光流×20
4. xy_coords_warped表示从source坐标加上光流后的坐标并且进一步归一化到[-1,1]并进一步调整维度以适应后续的grid_sample函数计算采样得到target_matches(这里要调整采样坐标范围归一化到[-1,1]是因为grid_sample中采样grid形参当为[-1,1]时（-1，-1）表示左上角，(1,1)表示右下角)
5. source_points就是第一帧对应的点图，source_anchor_validity表示筛选出像素对应的点相邻4个控制点node都合法的图
6. 通过grid_sample采样target_points得到target_matches
7. target_vadility是target_points中进一步需要保证深度处于合法范围的点对应的筛选掩码图
8. 因此target_matches_validity是进一步根据光流变换后的坐标采样的target_matches的掩码
9. 之后计算valid_source_points要求这个source帧的点图中的点要满足合法深度范围同时这个像素对应的三维点还要有4个对应的控制节点，因此深度不合法的点也自动筛选出去，valid_target_matches也是类似只不过只需要深度符合合法范围就可以
10. 如果需要预测权重，则输入需要准备mask_input是source的6通道数据以及采样的rgb和点图拼成的6通道数据并和features2进一步输入到mask_net预测权重
11. 最后合法的用来进行形变场估计的点对必须是source和soucr+flow采样的target都合法才行，因此valid_correspondences用来选取合法的用于优化形变场的点对
12. 如果使用了权重估计网络masknet则这里的correspondence_weights初始化为mask_pred估计的权重并进一步如果是在测试阶段，可以进一步对weights进行处理比如设定硬截断阈值等
13. 统计合法的点对数量，由于valid_correspondnces本质上是H*W的mask所以为1的地方就是合法的点对(其实许多筛选环节都是使用的掩码实现的)因此直接求和即可统计数量
14. 接着初始化一系列后面优化形变需要用到的参数包括node旋转与平移(分别使用旋转矩阵和平移向量)，node形变是否合法，是否合法求解，以及真正优化过程中计算迭代的损失并不是使用所有的合法点对而是有一个最大数量opt.gn_max_warped_points，因此deformed_points_pred用来存储形变场根据当前参数形变后的预测点位置，idxs是随机选取的点对的索引值
15. 这里的vec_to_skew_mat是一个[9,3]的张量用来后面对旋转进行旋转矩阵与轴角表示法转换处理的
16. 之后对batch_size逐个进行优化，首先需要对要优化的当前的motion_graph的规模进行检查保证nodes数量在一定范围内(范围可以自行设定)不合法会导致跳过形变场优化过程以及检查当前是否存在用来进行损失计算的匹配点对如果没有则无法计算优化损失也会导致跳过形变场的优化
17. 之后取出batch中每一个样本优化需要的图数据，这里的original_graph_nodes_i和graph_nodes_i我暂时赋值一样这里代码有问题
18. 之后根据valid_correspondences掩码图获取合法点对对应的图索引(u,v)并进一步在source_points和target_matches中进行选取选出这些合法点对的source与target gt坐标以及预测的xy_pixels_warped_filtered从source二维坐标经过光流后的在target_points中的采样二维坐标和对应的这些匹配点对对应的自适应权重correspondence_weights_filtered以及这些匹配点对对应的source_points的邻近4个控制节点索引source_anchors和source_weights
19. weight_info存储的total_corres_num存储的是合法匹配点对的数量，而total_corres_weight是对应的自适应权重的求和，这里通过求和的权重/匹配点对数量可以求得自适应权重网络对大量点对给出的平均权重置信度
20. 之后根据测试或者训练时设置的最大匹配点对数量对匹配点对进行随机选取
21. 接下来有一个环节是如果当前某个node cluster集群的nodes没有充足的匹配点对则要删除，这个操作可能可以进一步控制node数量不会过多但是是可选操作这里默认不需要结合了掩码以后控制节点个数并不会无限增长
22. 接下来创建graph_edge_pairs就是每一个node和其他最多8个邻近node建立有向图
23. 但是这里的graph_edge_pairs有的是不合法的因为并不是每一个node都有8个邻近node因此需要进行删除，valid_edges存储graph_edges_i中的合法边mask，之后进一步结合mask筛选出合法的idxs，并根据idxs筛选出合法的motion graph边和权重
24. 之后开始高斯牛顿迭代优化形变，首先初始化一些超参数包括迭代次数，data项(2d位置差距)，depth项(3d位置差距)以及刚性正则项的λ值以及学习率lm_factor
25. 开始优化前注意几个问题，实际上node的形变是轴角表示法+平移实现的，但是具体优化过程中可能会涉及到旋转矩阵和轴角表示法的转换，同时motion_graph一直存储的都是从标准空间形变到任意帧t的形变，因此先从上一个存储deformation_graph的mat中获取从标准空间到t-1帧的形变，而此次形变只是进一步优化从t-1->t的node形变，最后是累积的。但是这里还是有一个问题匹配点对是找的标准空间即frame0和frame t之间的，因此还是要求这两个图片差异不能过大至少要有对应关系，这里是不是可以进一步优化每一次直接训练t-1帧和t帧的形变即从t-1和t寻找匹配点对？
26. 接下来定义了三个data_increment_vec是辅助构建后面高斯牛顿迭代优化矩阵的结构向量都是间隔为3的递增序列，只不过开始的首项有区别
27. 以及还构建了arap_increment_vec辅助结构张量和记录当前优化求解是否是ill-pose
28. 接下来开始迭代求解，注意每迭代两次lm_factor要减半这是因为随着迭代求解后更新幅度需要减小类似于torch中的学习率
29. jacobian_data的维度是[匹配点对的数量*3个维度的坐标,关键点node的6个待优化参数]因此存储的是每一个匹配点对坐标对关键点的优化影响
30. deformed_points存储的是匹配点对中的source_points经过当前node控制形变后的预测的位置，而匹配点对中的target_matches是gt
31. 之后计算预测的deformed_points，计算方法就是根据没有给点的anchors获取被控制的邻近4个node并逐个计算绕node旋转平移后的位置的加权求和，注意source_weights是归一化的
32. 之后计算存储一些后面用于构造雅各比矩阵的中间变量
33. 注意weights_k和source_weights的区别，source-weights存储的是每一个node对source三位点的影响权重，而weights_k是其和自适应权重的乘积
34. 之后要注意看似又计算了一遍source点的形变，但是和之前的有所区别，这里只计算了旋转weighted_rotated_points_k同时权重还加入了自适应权重
35. 之后构造skew_symetric_mat_data这个是论文14页最上方的最后一项注意最后要修改为3*3格式
36. 之后首先构造雅各比矩阵中2d光流data项对于node平移的影响雅各比矩阵，再回顾一下雅各比矩阵维度是[3(对应点的三个坐标x,y,z)*点对个数,6\*(对应node6个待优化参数前三个表示旋转后3个表示平移)节点个数]，因此这里2d光流只使用了点的前2维坐标对平移的影响，因此注意雅各比矩阵的更新索引(这里的矩阵行数代表了使用的点对坐标维度，列数代表了对node待优化项的维度)，这里直接参考14页的公式实现即可这里涉及到对雅各比矩阵关于点的x,y对node平移项三个维度的更新
37. 而depth项对于平移的影响就只是点的z并且是1对节点对最后一个维度的跟新
38. 接着是计算2d光流项对于节点旋转的3个维度的更新，这里实现方法同时，还是要注意雅各比矩阵的索引之后即完成了雅各比矩阵的构造并检测雅各比矩阵是否值都合法
39. 同时构造2d光流项和深度项的残差，按照公式定义2d光流项就是光流项权重值×自适应权重值×source形变后的点投影到target后的2d坐标之差，注意这里也发现了source_weghts和correspondence_weights的区别，当我们计算点根据node形变的位置时只需要使用关键点node对非关键点的权重值，而correspondence是只参与雅各比与残差项的构造的，因此注意deformed_points的构造和weighted_rotated_points的计算先后顺序与实现上的细节公式不同，以上就是2d光流data项和depth data项关于残差和雅各比矩阵的构造方法
40. 之后是计算arap正则项的雅各比与残差部分，这里的雅各比矩阵定义为[边的个数*3，节点数\*6]并且实际上残差residual没有平方项，就是一范式这里和论文的公式11不同
41. 然后按照公式计算arap损失对节点各个维度的雅各比项并计算，注意雅各比矩阵的索引包含了损失对于哪个节点的哪个维度的影响，之后构建后也是判断正则雅各比项是否合法
42. 之后结合雅各比项和残差项构建A和b，并根据Ax=b使用线性求解器进行求解并拆解x前三维轴角表示的旋转为旋转矩阵，后三维为偏移量与t-1的累加
43. 之后使用当前优化后的关键点的motion再对source进行一次形变，注意这和之前优化的不一样这里是使用优化后的node带动形变，之前计算deformed_points用于计算损失，这里是为了后面调试可视化
44. 最后返回结果包括一开始用于计算2d光流的flow_data,以及优化后的node形变，是否优化合法，以及预测的形变后的点图，是否合法求解，预测自适应权重，以及匹配点对的信息包括根据光流得到的预测形变采样二维坐标，匹配点对的源点，合法源点，匹配点，以及匹配点对的mask和用于进行形变优化计算的形变点索引以及是否进行了上采样记录

### TSDF integrate函数(形变后融合)

1. 注意对比第一次integrate这里接受的是target数据即当前输入帧而非第一帧的数据
2. 这里由于graph_deformation_data不再是空即计算出来了从标准空间的数据到当前帧的motion_graph，因此fusion之前需要先把tsdf表示的几何形变到当前帧视角
3. 之后还是和第一次一样计算这些voxel的位置并筛选出在视窗之内的进行更新

### WarpField deform_tsdf函数

1. 虽然有points参数，但是我们都是将标准空间的tsdf形变到当前帧，因此直接从self.world_pts获取voxels点即可
2. 这里的旋转使用四元数表示以便进行插值
3. 接下来通过查询kdtree查询points中每一个点最近的4个控制节点nodes，但是要注意这里的points有的是不合法的即距离nodes很远这里后面会再筛选
4. 因此接下来将dist中超过2倍node影响距离的dist赋值为无穷大表示无法抵达
5. 之后计算每一个point最邻近的4个关键节点node对其的权重影响
6. 之后进行对points的形变，这里采用dqs，dqs和lbs的区别在于lbs是直接根据关键点node形变后的位置插值得到非关键点的位置，这种方法对于剧烈运动时会出现问题，而dqs是根据关键点node插值得到每一个非关键点自己的形变进行新位置的计算
7. 注意这里之后得到deform_world_pts之后才计算的合法的valid_points(还是掩码筛选)，因此实际上在dqs计算形变过程中有许多无用的操作这里可能可以先筛选出合法的做法更好
8. 之后返还，这里一定要返还合法点mask以便后续操作

### WarpField deform_world_points_dqs函数

1. 首先对权重进行归一化，注意有些点是没有合法的关键点的因此可能归一化后为nan即除零了此时就跳过形变，如果是合法的说明他有4个合法的控制关键点node
2. 这里具体的实现方法实际上和前面的差不多，只不过这里使用的是四元数版本表示的旋转，也是加权求和，注意当权值小于1e-6时可以认为这个关节点对points影响很小则直接跳过，因此这里和前面的优化形变场时的实现有些区别，这里可能受到控制的关节点个数少于4个，并且没有关节点控制的points则位置不变。

### updata_warpfield函数

1. 注意motion_graph存储的一直是标准空间的nodes静态属性比如顶点数，权重等，而nodes具体的每一个标准空间到每一帧的顶点形变存储在deform_graph_data中，因此这里我们添加新的控制顶点是基于标准空间计算因此传入的updated_mesh_verts实际上是标准空间fusion后的mesh顶点
2. 首先这些点都是合法的，查询kdtree找到每一个顶点的最近的控制节点，注意这里并不需要找4个，只需要找最近的1个，因为如果最近的一个控制节点距离其都很远超过阈值则说明这个区域需要添加新的控制节点
3. 如果确实存在需要添加新控制节点的情况，则进一步调用create_graph_data_using_depth的updata_graph函数进行motion_graph的更新，注意只传入那些没有控制节点的新mesh顶点
4. 注意以上只完成了motion_graph中新节点的添加等静态属性的更新我们还需要为当前的source中点重新计算其受控制的关键节点以及权重，因此进一步调用updata_live_frame_graph，在调用前我们需要传入source即第一帧的数据，因为只有部分像素对应的三维点是有效的受控制节点控制的因此需要进一步计算mask以及静态属性更新后的graph_data
5. 之后调用warpfield.update函数更新当前的graph_data,以及更新kdtree等
6. 以上只是完成了motion_graph中的静态属性的更新，包括添加新的关节点，边，权重以及source点的相关信息，我们还需要更新motion_graph的deformation信息即为新的关键点初始化形变因此调用update_warpfield_deformation函数

### create_graph_data_using_depth update_graph函数

1. 具体负责添加新初始化的控制节点并更新motion_graph，首先随机打乱这些mesh顶点，因此这些新的mesh顶点都将是公平的候选关键点nodes
2. 如果是一个新顶点那么就选取其为一个新的关键点之后继续循环，如果其他新的顶点已经和new_node_list的任意一个顶点距离小于node_coverage则将受其控制不再选为新的控制节点否则就认为是一个新的控制节点，注意new_node_list存储的并不是新的控制节点的三维坐标而只是索引值
3. 之后认为新的总控制节点就是当前motion_graph中的控制节点和新的控制节点
4. 之后需要为这些新节点寻找邻近关键节点，因此计算新节点与全部节点的距离因此new_node_distance_matrix维度为[新控制节点，新控制节点+motion_graph原先的节点]，之后也是只保存8个最近的邻近节点，很明显应该取[1:9]因为0是自己本身距离为0肯定最近，注意这里的nn_nodes存储的是最邻近的8个关键节点node的索引而不是距离因此接下来nn_dists是计算距离
5. 虽然取了最近的8个，但是nn_nodes中的最近8个邻近关键点的距离还是有超过2倍的控制距离的则也认为不可达将索引值赋值为-1
6. 之后计算nn_nodes中邻近关键点数量不少于3个的设置为合法关键节点，其他的也要认为是不合法的关键节点，这里通过生成removable_nodes_mask表示但是这里的mask实际上是索引值，之后就是删除new_node_list中的这些邻居关键节点过少的新控制节点
7. 之后才是真正的更新graph_data中的关键节点，注意new_node_list中存储的是顶点索引，具体的坐标还需要查询
8. 并更新graph_data的关键节点边
9. 之后nn_weights用于计算新的关键节点的边权重值，注意这里的代码我认为应该是nn_weights[nn_nodes ==-1] = np.inf即将不可达邻居的距离(暂时叫权重值)设置为无穷这样的话后面进一步利用exp计算权重值时距离远的边权重将接近于0
10. 之后也是进一步更新num_nodes个数以及计算关键节点所属群并删除所属群中节点数过少的关键节点自此完成了motion_graph静态属性的更新即添加新的节点以及边和边权重

### create_graph_data_using_depth update_live_frame_graph函数

1. 首先根据source的数据以及mask获取这些合法的点，之后重新计算motion_graph中的关键节点与这些source_points_valid的距离，并根据mask取出合法的像素点
2. 之后调用compute_pixel_anchors_geodesic_c重新计算这些点邻近的控制节点和权重，这里只是对之前合法的像素重新寻找更好的控制节点，这里之所以要更新source像素点对应的邻近关节点的信息是因为source中的点是要参与和target_match的correspondece的2d光流等data项的计算来优化motion_graph中关键节点的形变的，因此这里有必要更新pixel_anchors等

### update_warpfield_deformation函数

这里有两种更新策略一种是更简单的也是这里默认使用的将新节点的旋转平移全部初始化为单位矩阵旋转和零平移向量并添加到graph_deformation_data中，或者更合理是使用邻近点插值的方法
